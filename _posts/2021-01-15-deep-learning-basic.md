---
layout: post
title:  Deep Learning 기초
date:   2021-01-15
image:  .png
tags:   Data
---
## NN 기초

#### `퍼셉트론`
신경망을 이루는 가장 기본 단위로, 퍼셉트론은 다수의 신호(INPUT)를 입력받아서 하나의 신호(OUTPUT)를 출력한다.

#### `Weight`
INPUT으로 받은 값을 각 뉴런에 전달하게 되는데 그 과정에서 가중합을 활용한다. 즉, 가중치를 통해 활성화함수의 기울기를 변화시켜 결과 값에 대한 영향력의 크기를 결정한다.

#### `Bias`
가중합을 통해 각 뉴런으로 전달할 때 bias를 추가하여 연산하게 된다. bias를 통해 활성화함수를 왼쪽, 오른쪽으로 이동시켜 결과 값에 대한 영향력의 크기를 결정한다.

#### `활성화 함수`
* `sigmoid`
sigmoid는 0과 1 사이의 범위를 가지고 있으며, 이진 분류 문제에 적절하다. 그림에서 보는 것처럼 INPUT 값이 매우 크거나 작을 경우 기울기가 0에 가까워진다. 이러한 경우, 층이 깊을수록 작은 기울기 값들이 곱해지면서 기울기가 점점 작아지는 gradient vanishing 문제가 발생할 수 있다. 또한, 학습을 지그재그 형태로 만들어 학습이 느려지는 문제가 발생한다.
